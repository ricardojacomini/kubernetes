# group_vars/k8s-cluster.yml
---
# Core Cluster Configuration
cluster_name: "k8s-cluster"

# Network Architecture
networking:
  ip_family: "ipv4"  # Options: ipv4, ipv6, dual
  pod_network: 
    cidr: "192.168.1.0/24"
    allocation_pool: 
      start: "192.168.1.10"
      end: "192.168.1.254"
  service_network:
    cidr: "192.168.2.0/24"
    dns_ip: "{{ (service_network.cidr|ipaddr('network'))|ipaddr('+10') }}"  # CoreDNS IP

  dns:
    servers:
      - "{{ networking.service_network.dns_ip }}"  # Primary (CoreDNS)
      - "172.20.1.3"                               # Secondary
    domains:
      - "svc"
      - "svc.cluster.local"
      - "cluster.local"

  proxy_settings:
    no_proxy: >-
      {{
        [networking.pod_network.cidr, networking.service_network.cidr] +
        networking.dns.domains|map('regex_replace','^\.','*.' )|list
      }}

# Host-to-alias mapping
network_alias_ips:
  c267: 192.168.1.10
  c276: 192.168.1.11
  icgpu10: 192.168.1.12

network_alias_interface: eno1
network_alias_netmask: 255.255.255.0

# Kubelet Configuration
kubelet:
  base_flags:
    - "--container-runtime=remote"
    - "--container-runtime-endpoint=unix:///run/containerd/containerd.sock"
    - "--node-ip=$(hostname -I | awk '{print $1}')"
    - "--read-only-port=0"
    - "--protect-kernel-defaults=true"

  # GPU-specific flags (will be merged with base_flags for GPU nodes)
  gpu_flags:
    - "--feature-gates=DevicePlugins=true"
    - "--node-labels=nvidia.com/gpu=true"
    - "--register-with-taints=nvidia.com/gpu=true:NoSchedule"

# GPU Configuration
nvidia:
  device_plugin:
    enabled: true
    image: "nvcr.io/nvidia/k8s-device-plugin:v0.14.1"
    args:
      - "--mig-strategy={{ nvidia.mig.strategy | default('none') }}"
      - "--fail-on-init-error=true"
    resources:
      limits:
        nvidia.com/gpu: 1
    compat32: false

   # MIG Configuration (for A100/H100)
    mig:
      enabled: false
      strategy: "none"  # Options: none, single, mixed
      profiles: []
  
  # Feature Gates
  feature_gates:
    DevicePlugins: true
    MigPartitioned: false

  # Safety Checks
  requirements:
    min_driver_version: "525.85.12"
    min_cuda_version: "11.8"

# Docker Network Integration
docker:
  network:
    bip: "{{ (networking.pod_network.cidr|ipaddr('first_usable'))|ipaddr('+1')|ipaddr('net') }}"
    mtu: null
    no_proxy: "{{ networking.proxy_settings.no_proxy }}"
  storage:
    driver: "overlay2"
    opts: []
  gpu_config:
    default_runtime: "nvidia"
    runtimes:
      nvidia:
        path: "/usr/bin/nvidia-container-runtime"
        runtimeArgs: []

# Resource Management
resource_management:
  capacity:
    pods_per_node: 250
  reservations:
    kubelet:
      cpu: "500m"
      memory: "1Gi"
      ephemeral_storage: "1Gi"
    system:
      cpu: "500m"
      memory: "500Mi"
      ephemeral_storage: "1Gi"
  gpu_overrides:  # For high-density GPU nodes
    kubelet_reserved:
      cpu: "1000m"
      memory: "2Gi"
    system_reserved:
      cpu: "1000m"
      memory: "2Gi"

# GPU Defaults (overridable in host_vars)
gpu:
  node_labels:
    nvidia.com/gpu: "true"
  taints:
    - key: "nvidia.com/gpu"
      value: "true"
      effect: "NoSchedule"

# Offline Repositories
k8s_repos:
  ubuntu:
    gpg_key: "file:///opt/pki/kubernetes-key.gpg"
    repo_url: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] file:///opt/repos/kubernetes /"

